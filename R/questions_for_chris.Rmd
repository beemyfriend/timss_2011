---
title: "Questions For Chris"
author: "BeeMyFriend"
date: "February 18, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Intro

Hey Chris, 

I've been working on the 2011 TIMSS Math dataset and now I'm trying to model some of the student data. My goal is to predict the international benchmark scores for each student. I'm using Naive Bayes, Support Vector Models, Trees, and Random Forests to model the data. This is all kind of new to me so I'm not sure if I'm approaching the models correctly. 

The TIMSS data set is pretty big and has a lot of information for each of the students, teachers, and schools involved. I don't want to use every column provided because I think there is a lot of repetition and a big risk of overfitting the model. What I ended up doing was fitting each dataset to a Generalized Boosted Regression Model and letting *R*'s `gbm()` function figure out which columns would be the most influential in figuring out a student's benchmark scores. 

I've also made two iterations of the models. The first iteration tries to predict the benchmark scores provided by TIMSS which I named 'Advanced', 'High', 'Intermediate', 'Low', and 'Below Low'. The second iteration tries to predict a more generalized version of the benchmark scores which I named 'High', 'Intermediate', and 'Low'.

Below I made a table with the results of each model's confusion matrix. Each cell contains the correct rate - the percent of correctly predicted benchmark scores - for the models. I've included the individual benchmark scores correct rate along with both the overall correct rate and the correct rate if I guessed that every student were to receive a Below Low (or Low) benchmark score.

I have 4 main questions:

1. What are typical correct rates for models predicting the academic success for students? The TIMSS dataset does not include the school's geolocation or whether it is private or public, so I suspect that the models could definitely be better. However, I feel like anything near a 90% correct rate is near impossible.

2. What is the 'Jacknife' with regards to surveys? I don't have any background in surveys and there aren't any really good resources online for understanding what it is. The reason I ask is that there is a factor called 'JKZONE' which represents the 'The variable that captures the assignment of cases (typically students) to sampling zones.' The `gbm()` ranks this factor as really important in predicting the benchmark scores, but I don't want to use it if it is a factor that the TIMSS provides. That is, I don't want to use it until I can confirm that it is a predictor that can be derived independently of TIMSS.

3. Is reducing the amount of factors a valid approach for modeling? In the second iteration of the models I combined the 'Advanced' and 'High' benchmarks together and combined the 'Low' and 'Below Low' benchmarks together. Obviously, the prediction accuracy improved a lot, but I'm not sure if this cheapens the model. 

4. Are there any other models worth trying out? I don't really know what is typically done when analyzing survey/test data. 

Any help or advice you can give me would be awesome. 

Cheers,
Ben


## Correct Rates


## Influential Columns

